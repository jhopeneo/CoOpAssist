# LLM Provider API Keys
OPENAI_API_KEY=sk-your-openai-api-key-here
ANTHROPIC_API_KEY=sk-ant-your-anthropic-api-key-here

# LLM Provider Selection (openai, claude, ollama)
LLM_PROVIDER=openai

# LLM Model Configuration
LLM_MODEL=gpt-4-turbo-preview
LLM_TEMPERATURE=0.7
LLM_MAX_TOKENS=2000

# Embedding Configuration
EMBEDDING_PROVIDER=openai
EMBEDDING_MODEL=text-embedding-3-small

# Document Source - Network Share
# For Windows: Q:\ or //neonas-01/qmanuals
# For Linux: /mnt/q or mount point
QMANUALS_PATH=Q:\
# Alternative network path
QMANUALS_NETWORK_PATH=//neonas-01/qmanuals

# SMB Credentials (if needed for network access)
SMB_USERNAME=
SMB_PASSWORD=
SMB_DOMAIN=

# ChromaDB Configuration
CHROMA_DB_PATH=./data/chroma_db
CHROMA_COLLECTION_NAME=qmanuals

# Retrieval Settings
TOP_K=5
SIMILARITY_THRESHOLD=0.7

# Chunking Configuration
CHUNK_SIZE=800
CHUNK_OVERLAP=200

# Ingestion Performance Settings
# Number of parallel workers for document ingestion (1-32)
# Higher values = faster ingestion but more CPU/memory usage
INGESTION_WORKERS=4
# Number of documents to batch before adding to vector store
INGESTION_BATCH_SIZE=50

# Application Settings
APP_NAME=QmanAssist
APP_PORT=8501
LOG_LEVEL=INFO

# Streamlit Configuration (optional)
STREAMLIT_SERVER_PORT=8501
STREAMLIT_SERVER_ADDRESS=localhost
